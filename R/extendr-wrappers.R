# Generated by extendr: Do not edit by hand

# nolint start

#
# This file was created with the following call:
#   .Call("wrap__make_deltaR_wrappers", use_symbols = TRUE, package_name = "deltaR")

#' @usage NULL
#' @useDynLib deltaR, .registration = TRUE
NULL

#' Register cloud storage handlers (GCS, S3, Azure) for deltalake
#' Called from R's .onLoad to enable cloud storage support
register_cloud_handlers <- function() invisible(.Call(wrap__register_cloud_handlers))

#' Open a Delta Table at the specified path
#'
#' @param path Path to the Delta table.
#' @param storage_options Optional storage options for the backend.
delta_table_open <- function(path, storage_options) .Call(wrap__delta_table_open, path, storage_options)

#' Check if a path is a Delta Table
#'
#' @param path Path to check.
#' @param storage_options Optional storage options for the backend.
is_delta_table <- function(path, storage_options) .Call(wrap__is_delta_table, path, storage_options)

#' Execute a Delta Lake MERGE operation
#'
#' This function receives all merge configuration from R and executes
#' the merge in a single call, avoiding complex state management.
#'
#' @param table_uri Path to the Delta table
#' @param source_stream Arrow data stream for source data
#' @param predicate Main merge predicate (e.g., "target.id = source.id")
#' @param source_alias Alias for source table in expressions
#' @param target_alias Alias for target table in expressions
#' @param matched_update_clauses List of update clauses for matched rows
#' @param matched_delete_clauses List of delete clauses for matched rows
#' @param not_matched_insert_clauses List of insert clauses for unmatched source rows
#' @param not_matched_by_source_update_clauses List of update clauses for unmatched target rows
#' @param not_matched_by_source_delete_clauses List of delete clauses for unmatched target rows
#' @param storage_options Storage backend options (optional)
delta_merge_execute <- function(table_uri, source_stream, predicate, source_alias, target_alias, matched_update_clauses, matched_delete_clauses, not_matched_insert_clauses, not_matched_by_source_update_clauses, not_matched_by_source_delete_clauses, storage_options) .Call(wrap__delta_merge_execute, table_uri, source_stream, predicate, source_alias, target_alias, matched_update_clauses, matched_delete_clauses, not_matched_insert_clauses, not_matched_by_source_update_clauses, not_matched_by_source_delete_clauses, storage_options)

#' Write data to a Delta Lake table using WriteBuilder and LogicalPlan
#'
#' This function uses DataFusion's execution framework to write data, providing:
#' - Better error handling through the DataFusion pipeline
#' - Lazy schema casting (casts each batch on-the-fly)
#' - Proper backpressure handling for large datasets
#' - Memory-efficient streaming writes
#'
#' @param table_uri Path to the Delta table (will be created if it doesn't exist)
#' @param stream Arrow data stream (nanoarrow_array_stream)
#' @param mode Save mode: "append", "overwrite", "error", or "ignore"
#' @param partition_by Column names to partition by (optional)
#' @param name Table name (optional, used when creating new table)
#' @param description Table description (optional, used when creating new table)
#' @param storage_options Storage backend options (optional)
#' @param schema_mode How to handle schema evolution: "overwrite" or "merge" (optional)
#' @param target_file_size Target file size in bytes (optional)
delta_write <- function(table_uri, stream, mode, partition_by, name, description, storage_options, schema_mode, target_file_size) .Call(wrap__delta_write, table_uri, stream, mode, partition_by, name, description, storage_options, schema_mode, target_file_size)

#' Create a new empty Delta Lake table
#'
#' @param table_uri Path where the table will be created
#' @param schema Arrow schema for the table
#' @param partition_by Column names to partition by (optional)
#' @param name Table name (optional)
#' @param description Table description (optional)
#' @param storage_options Storage backend options (optional)
#' @param configuration Table configuration properties (optional)
delta_create <- function(table_uri, schema, partition_by, name, description, storage_options, configuration) .Call(wrap__delta_create, table_uri, schema, partition_by, name, description, storage_options, configuration)

DeltaTableInternal <- new.env(parent = emptyenv())

DeltaTableInternal$version <- function() .Call(wrap__DeltaTableInternal__version, self)

DeltaTableInternal$uri <- function() .Call(wrap__DeltaTableInternal__uri, self)

DeltaTableInternal$get_files <- function() .Call(wrap__DeltaTableInternal__get_files, self)

DeltaTableInternal$num_files <- function() .Call(wrap__DeltaTableInternal__num_files, self)

DeltaTableInternal$metadata <- function() .Call(wrap__DeltaTableInternal__metadata, self)

DeltaTableInternal$schema <- function() .Call(wrap__DeltaTableInternal__schema, self)

DeltaTableInternal$history <- function(limit) .Call(wrap__DeltaTableInternal__history, self, limit)

DeltaTableInternal$load_version <- function(version) .Call(wrap__DeltaTableInternal__load_version, self, version)

DeltaTableInternal$load_datetime <- function(datetime_str) .Call(wrap__DeltaTableInternal__load_datetime, self, datetime_str)

DeltaTableInternal$compact <- function(target_size, max_concurrent_tasks, min_commit_interval_ms, partition_filters) .Call(wrap__DeltaTableInternal__compact, self, target_size, max_concurrent_tasks, min_commit_interval_ms, partition_filters)

DeltaTableInternal$vacuum <- function(retention_hours, dry_run, enforce_retention_duration) .Call(wrap__DeltaTableInternal__vacuum, self, retention_hours, dry_run, enforce_retention_duration)

DeltaTableInternal$partition_columns <- function() .Call(wrap__DeltaTableInternal__partition_columns, self)

#' @export
`$.DeltaTableInternal` <- function (self, name) { func <- DeltaTableInternal[[name]]; environment(func) <- environment(); func }

#' @export
`[[.DeltaTableInternal` <- `$.DeltaTableInternal`


# nolint end
