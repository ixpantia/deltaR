# Generated by extendr: Do not edit by hand

# nolint start

#
# This file was created with the following call:
#   .Call("wrap__make_deltaR_wrappers", use_symbols = TRUE, package_name = "deltaR")

#' @usage NULL
#' @useDynLib deltaR, .registration = TRUE
NULL

#' Open a Delta Table at the specified path
#' @export
delta_table_open <- function(path, storage_options) .Call(wrap__delta_table_open, path, storage_options)

#' Check if a path is a Delta Table
#' @export
is_delta_table <- function(path, storage_options) .Call(wrap__is_delta_table, path, storage_options)

#' Write data to a Delta Lake table using WriteBuilder and LogicalPlan
#'
#' This function uses DataFusion's execution framework to write data, providing:
#' - Better error handling through the DataFusion pipeline
#' - Lazy schema casting (casts each batch on-the-fly)
#' - Proper backpressure handling for large datasets
#' - Memory-efficient streaming writes
#'
#' @param table_uri Path to the Delta table (will be created if it doesn't exist)
#' @param data Arrow data stream (nanoarrow_array_stream)
#' @param mode Save mode: "append", "overwrite", "error", or "ignore"
#' @param partition_by Column names to partition by (optional)
#' @param name Table name (optional, used when creating new table)
#' @param description Table description (optional, used when creating new table)
#' @param storage_options Storage backend options (optional)
#' @param schema_mode How to handle schema evolution: "overwrite" or "merge" (optional)
#' @param target_file_size Target file size in bytes (optional)
#' @export
delta_write <- function(table_uri, stream, mode, partition_by, name, description, storage_options, schema_mode, target_file_size) .Call(wrap__delta_write, table_uri, stream, mode, partition_by, name, description, storage_options, schema_mode, target_file_size)

#' Create a new empty Delta Lake table
#'
#' @param table_uri Path where the table will be created
#' @param schema Arrow schema for the table
#' @param partition_by Column names to partition by (optional)
#' @param name Table name (optional)
#' @param description Table description (optional)
#' @param storage_options Storage backend options (optional)
#' @param configuration Table configuration properties (optional)
#' @export
delta_create <- function(table_uri, schema, partition_by, name, description, storage_options, configuration) .Call(wrap__delta_create, table_uri, schema, partition_by, name, description, storage_options, configuration)

DeltaTableInternal <- new.env(parent = emptyenv())

DeltaTableInternal$version <- function() .Call(wrap__DeltaTableInternal__version, self)

DeltaTableInternal$uri <- function() .Call(wrap__DeltaTableInternal__uri, self)

DeltaTableInternal$get_files <- function() .Call(wrap__DeltaTableInternal__get_files, self)

DeltaTableInternal$num_files <- function() .Call(wrap__DeltaTableInternal__num_files, self)

DeltaTableInternal$metadata <- function() .Call(wrap__DeltaTableInternal__metadata, self)

DeltaTableInternal$schema <- function() .Call(wrap__DeltaTableInternal__schema, self)

DeltaTableInternal$history <- function(limit) .Call(wrap__DeltaTableInternal__history, self, limit)

DeltaTableInternal$load_version <- function(version) .Call(wrap__DeltaTableInternal__load_version, self, version)

DeltaTableInternal$load_datetime <- function(datetime_str) .Call(wrap__DeltaTableInternal__load_datetime, self, datetime_str)

DeltaTableInternal$vacuum <- function(retention_hours, dry_run, enforce_retention_duration) .Call(wrap__DeltaTableInternal__vacuum, self, retention_hours, dry_run, enforce_retention_duration)

DeltaTableInternal$partition_columns <- function() .Call(wrap__DeltaTableInternal__partition_columns, self)

#' @export
`$.DeltaTableInternal` <- function (self, name) { func <- DeltaTableInternal[[name]]; environment(func) <- environment(); func }

#' @export
`[[.DeltaTableInternal` <- `$.DeltaTableInternal`


# nolint end
